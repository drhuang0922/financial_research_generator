[core]
# The home folder for airflow, default is ~/airflow
airflow_home = /opt/airflow

# The executor class that airflow should use. Options include SequentialExecutor, LocalExecutor, CeleryExecutor, and more
executor = LocalExecutor

# The SQL connection string for the metadata database. Default is sqlite:///airflow.db
sql_alchemy_conn = postgresql+psycopg2://<user>:<password>@<host>:<port>/<database>

# The location where airflow should store its log files
dags_folder = /opt/airflow/dags
base_log_folder = /opt/airflow/logs

# The maximum number of parallel task instances that should run across all workers
parallelism = 32
dag_concurrency = 16

# The amount of parallelism as a multiple of the available cores
parallelism_factor = 0.8

# The maximum number of active DAG runs per DAG
max_active_runs_per_dag = 16

# The maximum number of retries that should be allowed for each task instance
max_retry_delay = 300

# The amount of time in seconds that airflow should wait between retrying failed task instances
retry_delay = 30

# The time zone that airflow should use for scheduling tasks
default_timezone = UTC

# The amount of time in seconds that a task instance can run before being killed
task_timeout = 600

# The email address that airflow should use to send notifications
email_backend = airflow.utils.email.send_email_smtp
smtp_host = localhost
smtp_starttls = True
smtp_ssl = False
smtp_port = 25
smtp_user = airflow@example.com
smtp_password = password
smtp_mail_from = airflow@example.com

[webserver]
# The port number that the airflow webserver should listen on
web_server_port = 8080

# The base URL for the airflow webserver. Default is http://localhost:8080
base_url = http://localhost:8080

# The amount of time in seconds that airflow should wait for the webserver to start up
web_server_startup_timeout = 60

# The amount of time in seconds that airflow should wait for a task instance to complete before timing out
web_server_worker_timeout = 120

# The secret key that airflow should use for CSRF protection
csrf_token_secret = mysecretkey

[scheduler]
# The amount of time in seconds that airflow should wait between scheduling tasks
scheduler_interval = 30

# The amount of time in seconds that airflow should wait between checking for new DAGs or changes to existing DAGs
min_file_process_interval = 5

# The amount of time in seconds that airflow should wait between heartbeat messages sent to the database
scheduler_heartbeat_sec = 10

# The amount of time in seconds that airflow should wait between checking for orphaned task instances
orphaned_tasks_check_interval_sec = 300

# The amount of time in seconds that a task instance can be running before being considered as "running too long"
run_duration_limit = 14400

# The amount of time in seconds that a DAG run can be "running too long" before being marked as failed
dag_file_processor_timeout = 120

# The number of seconds after a DAG run completes that the scheduler should wait before starting a new DAG run
dag_dir_list_interval = 300

# The maximum number of active DAG runs that the scheduler should allow at any one time
max_active_runs = 16
